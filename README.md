ğŸ§  Medical Chatbot
An intelligent Medical Chatbot built with Flask, LangChain, Pinecone, and Groq LLM, designed to answer health-related questions using retrieval-augmented generation (RAG).
This system leverages Hugging Face embeddings and a Pinecone vector database to fetch the most relevant medical information and generate accurate, context-aware responses.

ğŸš€ Features
ğŸ©º Medical Q&A System â€“ Answers user questions based on medical documents or indexed data.
âš™ï¸ RAG Pipeline â€“ Combines document retrieval and LLM reasoning for fact-based answers.
ğŸ§© Pinecone Vector Store Integration â€“ Stores and retrieves medical embeddings efficiently.
ğŸ¤– Groq Llama 3.1 Model â€“ Generates coherent and contextually relevant responses.
ğŸŒ Flask Web App â€“ Simple web interface for chat interaction (chat.html).
ğŸ”’ Environment Secure â€“ Uses .env for managing API keys securely.
ğŸ§± Tech Stack

Component	Description
Flask	Web framework for serving the chatbot UI and API
LangChain	Framework for chaining LLM and retrieval logic
Groq (Llama 3.1-8B Instant)	Language model used for response generation
Pinecone	Vector database for semantic search and retrieval
Hugging Face Embeddings	Used to convert text documents into vector form
HTML / JS	Frontend for user chat interface
âš™ï¸ Setup Instructions
1. Clone the Repository
git clone https://github.com/your-username/medical-chatbot.git
cd medical-chatbot

2. Create a Virtual Environment
python -m venv venv
source venv/bin/activate   # For Linux/Mac
venv\Scripts\activate      # For Windows

3. Install Dependencies
pip install -r requirements.txt

4. Set Up Environment Variables
Create a .env file in the root directory:
PINECONE_API_KEY=your_pinecone_api_key
GROQ_API_KEY=your_groq_api_key

5. Run the Flask App
python app.py


Visit the app in your browser at:
http://localhost:8080
ğŸ§© Project Structure
medical-chatbot/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ helper.py             # Handles embeddings and vector store setup
â”‚   â”œâ”€â”€ prompt.py             # Contains the system prompt and templates
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ chat.html             # Web UI for chatting with the bot
â”‚
â”œâ”€â”€ app.py                    # Main Flask application
â”œâ”€â”€ .env                      # Environment variables
â”œâ”€â”€ requirements.txt          # Dependencies
â””â”€â”€ README.md                 # Documentation

ğŸ§  How It Works
Embedding Generation:
Medical documents are embedded using Hugging Face embeddings.
Vector Storage:
Embeddings are stored in a Pinecone index (medical-chatbot).
Retrieval:
When a user asks a question, the system retrieves the top 3 (k=3) relevant chunks.
Response Generation:
The retrieved context is passed to Llama 3.1 through LangChain for generating the final medical answer.

ğŸ§¾ Example Query
User: â€œWhat are the symptoms of hypertension?â€
Bot: â€œCommon symptoms of hypertension include headaches, shortness of breath, dizziness, or nosebleeds. However, it is often asymptomatic and requires regular monitoring.â€

âš ï¸ Disclaimer
This chatbot is for educational and informational purposes only.
It is not a substitute for professional medical advice, diagnosis, or treatment.
Always consult a qualified healthcare provider for any medical concerns.

ğŸ“§ Contact
Developer: Mahnoor Amjad
Field: AI/ML | NLP | Deep Learning | Data Science
